---
create: 2025-04-10 13:15
---
# 网络层概述、路由器内部

本章重点关注网络层的**数据平面**，即网络层中涉及**转发**数据报（分组）的功能。
### 🗺️ 网络层：“数据平面”路线图

1.  **网络层概述**: 数据平面 vs 控制平面
2.  **路由器内部**: 输入端口、交换结构、输出端口、缓存管理与调度
3.  **IP 协议**: 数据报格式、寻址、NAT、IPv 6
4.  **通用转发与 SDN**: Match+Action 范式
5.  **中间件**

---

###  基础概念

#### 🌍 网络层服务与协议

*   **核心任务**: 将**报文段**从发送主机传输到接收主机。
    *   **发送方**: 将传输层报文段**封装**成数据报，交给链路层。
    *   **接收方**: 从链路层接收数据报，**解封装**后将报文段交给传输层。
*   **协议实例**: 网络层协议运行在**每一台**互联网设备上，包括主机和路由器。
*   **路由器的作用**:
    *   检查**所有**流经它的 IP 数据报的**首部字段**。
    *   根据首部信息（主要是目的地址）将数据报从合适的**输入端口**转移到合适的**输出端口**，实现数据报沿着端到端路径的**转发**。

#### ➡️ 转发vs. 🗺️ 路由

这是网络层**最关键**的两个功能：

1.  **转发** 🚗
    *   **定义**: 将分组（数据报）从路由器的**输入链路**移动到合适的**输出链路**的动作。
    *   **特点**:
        *   发生在**数据平面**。
        *   是**本地**的、**每个路由器**独立执行的功能。
        *   时间尺度短（纳秒级）。
    *   **类比**: 通过一个高速公路**立交桥**的过程。

2.  **路由** 🧭
    *   **定义**: 确定分组从**源**到**目的**所经过的**路径**（即一系列路由器的选择）的过程。
    *   **特点**:
        *   发生在**控制平面**。
        *   是**网络范围**的逻辑功能。
        *   涉及**路由算法**。
        *   时间尺度长（秒级，计算路由表）。
    *   **类比**: **规划**从出发地到目的地的**整个行程路线**。

---

### ✈️ 数据平面vs. 🧠 控制平面

#### 数据平面
*   **功能**: **本地的**、**每个路由器**执行的功能。
*   **任务**: 决定到达路由器输入端口的数据报**如何**被转发到输出端口。
*   **依据**: 直接利用**转发表**，通过查找数据报首部值来决定输出端口。
*   **例子**: 如下图，头部值为 `0111` 的分组到达，查表后决定从端口 `2` 转发出去。

#### 控制平面
*   **功能**: **网络范围**的逻辑。
*   **任务**: 决定数据报在路由器**之间**如何路由，即确定从源主机到目的主机的**端到端路径**。
**实现方式**:
##### 🏛️ 传统方式：每个路由器上的控制平面

*   每个路由器内部都运行着路由算法组件。
*   这些组件相互交互（通过路由协议），共同计算出转发表。
*   控制平面逻辑与数据平面转发紧密耦合在同一个设备中。
* ![Pasted image 20250410142101](Pic/Pasted%20image%2020250410142101.png)
##### 💡 SDN 方式：远程控制平面

*   **远程控制器** 计算转发表。
*   控制器将计算好的转发表**安装**到各个路由器中。
*   路由器主要负责根据下发的转发表进行**简单的数据平面转发**。
*   控制平面与数据平面**解耦**。
* ![Pasted image 20250410142112](Pic/Pasted%20image%2020250410142112.png)
---

### ✉️ 网络层服务模型

网络层为传输数据报的“通道”提供什么样的服务模型？

*   **单个数据报的服务示例**:
    *   保证交付 👍
    *   保证在 40 ms 内交付 ⏱️
*   **数据报流的服务示例**:
    *   按序数据报交付 🔢
    *   保证流的最小带宽 📶
    *   限制分组间间隔的变化（低抖动）〰️

#### 🌐 互联网的服务模型：尽力而为

| 网络架构   | 服务模型     | 带宽       | 丢失 | 有序 | 定时 |
| :--------- | :----------- | :--------- | :--- | :--- | :--- |
| **互联网** | **尽力而为** | **无保证** | **否** | **否** | **否** |
| ATM        | CBR          | 固定速率   | 是   | 是   | 是   |
| ATM        | ABR          | 最低保证   | 否   | 是   | 否   |
| 互联网     | IntServ| 是     | 是   | 是   | 是   |
| 互联网     | DiffServ| 可能   | 可能 | 可能 | 否   |

**互联网的“尽力而为”服务模型意味着：**
*   **不保证**:
	*   分组一定能成功交付。
	*   分组交付的时延。
	*   分组按序到达。
	*   端到端可用带宽。
#### 对“尽力而为”服务的反思

尽管缺乏保证，互联网的“尽力而为”模型非常成功，原因包括：

*   **机制简单**: 易于实现和广泛部署。
*   **足够带宽**: 通过**超额配置** 带宽，使得实时应用（如语音、视频）在“大多数时候”性能“足够好”。
*   **应用层补充**: 复制的、分布式的应用层服务（如 CDN、数据中心）将服务部署在靠近用户的地方，改善体验。
*   **拥塞控制**: 传输层（如 TCP）的拥塞控制机制有助于管理网络资源，应对弹性服务需求。

---

### ⚙️ 路由器内部结构

让我们深入了解路由器的关键组件：

#### 📐 路由器体系结构概览

一个通用的路由器主要由以下几部分组成：

1.  **输入端口**
2.  **交换结构**
3.  **输出端口**
4.  **路由处理器**

*   **数据平面**: 主要由输入端口、交换结构、输出端口组成，负责**硬件**实现的高速分组转发（纳秒级）。
*   **控制平面**: 主要由路由处理器实现，负责执行路由协议、维护路由表、计算转发表（通过**软件**，毫秒级）。

#### 📥 输入端口功能

输入端口执行数据平面的几个关键功能：

1.  **物理层**: 接收比特流。
2.  **链路层**: 将比特流组装成帧，执行链路层协议。
3.  **网络层**:
    *   **解封装**数据报。
    *   **查找**: 使用数据报的**目的地址**在**转发表**中查找对应的输出端口。这是核心功能。
    *   **转发**: 将数据报送往交换结构。
    *   **排队**: 如果数据报到达速率超过转发到交换结构的速率，则需要缓存（排队）。

*   **目标**: 以**线速**完成输入端口处理，避免成为瓶颈。
*   **实现**: **分布式交换**，查找和转发功能实现在每个输入端口上，不需路由处理器参与。转发表由路由处理器（控制平面）计算并下发。

##### ➡️ 基于目的地的转发 vs. 通用转发

*   **基于目的地的转发**:
    *   传统方式。
    *   转发决策**仅**基于数据报的**目的 IP 地址**。
*   **通用转发**:
    *   转发决策可以基于数据报**首部**的**任意字段组合**。
    *   这是 SDN 和 OpenFlow 的基础。

##### 🔍 最长前缀匹配

当转发表包含**重叠的地址范围**时，如何决定使用哪条表项？

最长前缀匹配规则：
-   查找转发表时，选择与数据报目的地址 **匹配前缀最长** 的那条表项。

*   **示例转发表**:

| 目的地址范围                          | 输出链路接口 |
| :------------------------------ | :----- |
| `11001000 00010111 00010`...    | 0      |
| `11001000 00010111 00011000`... | 1      |
| `11001000 00010111 00011`...    | 2      |
| `otherwise`                     | 3      |

*   **例子**:
    1.  目的地址: `11001000 00010111 00011000 10101010`
        *   **不** 匹配表项 0
        *   匹配表项 1
        *   匹配表项 2
        *   **最长匹配是表项 1** -> 选择接口 1。

*   **实现**: 通常使用 **TCAM** 存储转发表。TCAM 可以在一个时钟周期内完成查找，与表大小无关，速度非常快。

#### ↔️ 交换结构

*   **功能**: 将分组从输入端口**实际传输**到输出端口。
*   **目标**: 交换速率足够高，理想情况下为 `N x 输入链路速率`。
*   **主要类型**:
    1.  **经内存交换**:
        *   早期路由器，类似传统计算机。
        *   输入端口将分组复制到 **CPU 控制下的系统内存**，CPU 查找转发表，再将分组从内存复制到输出端口缓冲区。
        *   **瓶颈**: 内存带宽（每个分组需两次通过系统总线）。速度慢。
    2.  **经总线交换**:
        *   输入端口将分组直接通过**共享总线**传输到输出端口（需要加一个内部标签指示目标输出端口）。
        *   **瓶颈**: 总线带宽。同一时间只能有一个分组在总线上传输，存在**总线竞争**。适用于小型或低速路由器。
    3.  **经互连网络交换**:
        *   使用更复杂的互连结构（如**交叉开关 Crossbar**, Clos 网络）连接输入和输出端口。
        *   允许**并行**传输多个分组，只要它们的目的输出端口不同。
        *   **优点**: 可扩展性好，速度快，是现代高速路由器的主要方式。
        *   **实现细节**:
            *   **Crossbar**: N x N 的开关阵列，可以同时连接 N 对输入/输出端口。
            *   **多级交换结构**: 用多个小型的交换单元构建大型交换结构。
            *   **并行交换平面**: 使用多个并行的交换结构（平面）来进一步提高总交换容量（如 Cisco CRS）。

#### ⏳ 端口排队

##### 1. 输入端口排队

*   **原因**: 如果交换结构的速率**低于**所有输入端口的总速率，分组在到达交换结构前就可能需要在输入端口排队。
*   **问题**: **队头阻塞**
    *   **现象**: 排在队列**第一个**的分组，因为其**目标输出端口**暂时**忙碌**（例如，总线被占用，或 Crossbar 的输出端口冲突），而**阻塞**了队列中**后面**所有**其他**分组（即使这些分组的目标输出端口是空闲的）的转发。
    *   **后果**: 降低了交换结构的吞吐量。

##### ❗ 2. 输出端口排队- 非常重要 ❗

*   **原因**: 当分组从交换结构到达输出端口的速率**超过**该输出链路的传输速率时，分组需要在输出端口的**缓冲区** 中排队等待发送。
*   **后果**:
    *   **排队延迟**: 分组在缓冲区中等待的时间。
    *   **丢包**: 如果缓冲区**已满**，新到达的分组将被**丢弃**。这是网络**拥塞** 的主要表现形式之一。
*   **关键机制**:
    *   **缓存管理**: 决定当缓冲区满时**丢弃哪个分组**。
        *   **尾丢弃**: 丢弃新到达的分组（最简单）。
        *   **优先丢弃**: 基于优先级丢弃分组。
        *   **主动队列管理**, 如 RED: 在缓冲区**将满**时，**概率性**地丢弃分组，向发送方发出拥塞信号。
        *   **标记**: 不丢弃，而是在分组头部设置标记（如 ECN - Explicit Congestion Notification），当发送方收到带有 ECN 拥塞标记（值为 10）的分组的确认（ACK）时，它会意识到网络中发生了拥塞。
    *   **分组调度**: 决定缓冲区中**哪个分组下一个被发送**。
        *   **先来先服务**: 按到达顺序发送。简单，但无法区分服务。
        *   **优先级调度**: 将分组分成不同优先级类别，优先发送高优先级分组。可能导致低优先级分组“饿死”。
        *   **轮询调度（RR）**: 为每个类别设置一个队列，轮流从每个非空队列中发送一个分组。更公平。
        *   **加权公平排队**: RR 的泛化，每个类别分配一个**权重**，按权重比例分配带宽。可以提供最小带宽保证和差分服务。

*   **缓存大小考虑**:
    *   **经验法则**，采用**带宽时延积**: 缓存大小 ≈ RTT × C(带宽，bits/second)。
    *   **近期研究**: 对于大量 TCP 流，缓存大小 ≈ RTT × C / √N。
    *   **过大缓存**: 会导致很高的排队延迟，损害实时应用和 TCP 响应速度。目标是“保持瓶颈链路刚好占满，但不要更满”。

---