### **期末考试模拟题 (基于第二章：应用层)**

**说明:** 请详细回答以下问题，答案需要清晰、准确，并结合本章所学概念进行阐述。

---

#### **第一题：应用层体系结构与性能分析 (25分)**

网络应用主要采用两种体系结构：客户机/服务器（Client-Server）和对等（Peer-to-Peer, P2P）。

**(a) (9分)** 请详细比较这两种体系结构的特点，包括服务器的角色、可扩展性（scalability）和对基础设施的依赖。

**(b) (16分)** 假设一个服务器需要向 `N` 个对等方（Peers）分发一个大小为 `F` 的文件。服务器的上传速率为 $u_s$，每个对等方的下载速率为 $d_i$，上传速率为 $u_i$。为简化分析，我们假设所有对等方的下载速率都是 $d_{min}$，上传速率都是 $u$。
1.  写出在 **客户机/服务器模式**下，分发文件所需的最短时间 $D_{C-S}$ 的表达式（用 $F, u_s, N, d_{min}$ 表示），并解释表达式中各项的含义。
2.  写出在 **P2P模式**下，分发文件所需的最短时间 $D_{P2P}$ 的表达式（用 $F, u_s, N, d_{min}, u$ 表示），并解释表达式中各项的含义。
3.  假设 $F = 1.5$ GB， $u_s = 30$ Mbps， $u = 5$ Mbps， $d_{min} = 20$ Mbps。当 `N=30` 时，分别计算 $D_{C-S}$ 和 $D_{P2P}$ 的值，并分析为什么P2P模式在这种大规模分发场景下更高效。(提示: 1 GB = 1024 MB, 1 MB = 1024 KB, 1KB = 1024 Bytes, 1 Byte = 8 bits)

**【解析】**

**(a) 体系结构对比:** (参考幻灯片 2-6, 2-7)
*   **客户机/服务器 (Client-Server) 结构:**
    *   **服务器角色:** 有一个“永远在线”（always-on）的服务器，它拥有固定的IP地址，并等待客户端的请求。服务器负责提供所有服务和数据。
    *   **可扩展性:** 扩展性较差。随着客户端数量的增加，单一服务器会成为性能瓶颈，需要投入大量资金在数据中心进行服务器集群的扩展和维护。
    *   **基础设施依赖:** 严重依赖于数据中心和服务器的性能与带宽。

*   **对等 (P2P) 结构:**
    *   **服务器角色:** 通常没有专用的、永远在线的服务器。任意端系统（对等方）之间可以直接通信。每个对等方既是服务的请求者，也是服务的提供者。
    *   **可扩展性:** 具有**自扩展性 (self-scalability)**。每个新加入的对等方在带来服务需求的同时，也贡献了新的服务能力（如上传带宽），使得系统总容量随用户数增加而增长。
    *   **基础设施依赖:** 不依赖于昂贵的集中式服务器基础设施，管理更为复杂，因为对等方是间歇性连接且IP地址可能动态变化。

**(b) 性能计算与分析:** (参考幻灯片 2-77, 2-78)
1.  **客户机/服务器分发时间:**
    *   表达式: $D_{C-S} \geq \max \left\{ \frac{NF}{u_s}, \frac{F}{d_{min}} \right\}$
    *   **含义:**
        *   $\frac{NF}{u_s}$: 服务器必须将文件的 `N` 个副本依次上传，这是服务器端的瓶颈。总上传数据量为 $NF$，除以服务器上传速率 $u_s$，得到服务器完成所有上传任务的时间。
        *   $\frac{F}{d_{min}}$: 下载速度最慢的那个客户端接收完整个文件所需的时间，这是客户端侧的瓶颈。
        *   总时间取决于这两个瓶颈中更长的那个。

2.  **P2P分发时间:**
    *   表达式: $D_{P2P} \geq \max \left\{ \frac{F}{u_s}, \frac{F}{d_{min}}, \frac{NF}{u_s + \sum_{i=1}^{N} u_i} \right\}$  (用题目给定符号: $D_{P2P} \geq \max \left\{ \frac{F}{u_s}, \frac{F}{d_{min}}, \frac{NF}{u_s + N \cdot u} \right\}$)
    *   **含义:**
        *   $\frac{F}{u_s}$: 服务器至少需要将文件完整上传一次，这是P2P网络中服务器的最小责任。
        *   $\frac{F}{d_{min}}$: 下载速度最慢的客户端接收完文件所需的时间，与C/S模式相同。
        *   $\frac{NF}{u_s + N \cdot u}$: 这是P2P模式的核心。系统总共需要分发 $NF$ 的数据量。P2P网络中的总上传能力是服务器的上传能力 $u_s$ 与所有 `N` 个对等方贡献的上传能力之和 $N \cdot u$。此项代表了整个系统总上传能力的瓶颈。

3.  **计算与分析:**
    *   **单位换算:** $F = 1.5 \text{ GB} = 1.5 \times 1024 \times 1024 \times 1024 \times 8 \text{ bits} \approx 1.288 \times 10^{10} \text{ bits}$。
        *   为简化计算，通常在网络问题中用 $1G = 10^9$ 来估算。$F = 1.5 \text{ GBytes} = 12 \text{ Gbits} = 12 \times 10^9 \text{ bits}$。
    *   **计算 $D_{C-S}$:**
        *   服务器瓶颈: $\frac{NF}{u_s} = \frac{30 \times (12 \times 10^9 \text{ bits})}{30 \times 10^6 \text{ bps}} = 12000 \text{ s}$
        *   客户端瓶颈: $\frac{F}{d_{min}} = \frac{12 \times 10^9 \text{ bits}}{20 \times 10^6 \text{ bps}} = 600 \text{ s}$
        *   $D_{C-S} = \max\{12000, 600\} = 12000 \text{ s} \approx 3.33 \text{ 小时}$。
    *   **计算 $D_{P2P}$:**
        *   服务器瓶颈: $\frac{F}{u_s} = \frac{12 \times 10^9 \text{ bits}}{30 \times 10^6 \text{ bps}} = 400 \text{ s}$
        *   客户端瓶颈: $\frac{F}{d_{min}} = \frac{12 \times 10^9 \text{ bits}}{20 \times 10^6 \text{ bps}} = 600 \text{ s}$
        *   系统总上传能力瓶颈: $\frac{NF}{u_s + N \cdot u} = \frac{30 \times (12 \times 10^9 \text{ bits})}{(30 \times 10^6 + 30 \times 5 \times 10^6) \text{ bps}} = \frac{360 \times 10^9}{180 \times 10^6} = 2000 \text{ s}$
        *   $D_{P2P} = \max\{400, 600, 2000\} = 2000 \text{ s} \approx 33.3 \text{ 分钟}$。
    *   **分析:** 计算结果表明，P2P模式的效率远高于C/S模式。原因是C/S模式的分发时间与用户数 `N` 成线性关系，服务器负担极重。而P2P模式利用了每个对等方的上传能力，系统的总服务能力随着用户数 `N` 的增加而增加，有效分担了服务器的压力，使得分发时间增长缓慢，体现了其优越的**自扩展性**。

---

#### **第二题：HTTP协议与状态管理 (25分)**

HTTP是Web的核心应用层协议。

**(a) (9分)** HTTP被称为“无状态协议 (stateless protocol)”。请解释什么是无状态协议，并说明这种设计的优缺点。然后详细描述Cookies是如何被用来在无状态的HTTP上维持用户会话状态的（请说明cookie的四个组成部分及其交互过程）。

**(b) (16分)** 假设一个用户请求一个网页，该网页包含1个基本的HTML文件和10个嵌入的JPEG图像。HTML文件大小为100 KB，每个JPEG图像大小为500 KB。客户端与服务器之间的往返时延（RTT）为100ms。链路带宽为10 Mbps。
1.  计算在**非持续HTTP (Non-persistent HTTP)**下，获取整个网页内容所需的总时间。假设TCP连接建立需要1个RTT。
2.  计算在带流水线的**持续HTTP (Persistent HTTP with pipelining)**下，获取整个网页内容所需的总时间。

**【解析】**

**(a) HTTP状态管理与Cookies:** (参考幻灯片 2-20, 2-32, 2-33, 2-34)
*   **无状态协议:** 指服务器不保存任何关于过去客户端请求的历史信息。每个请求都被独立处理，服务器不记得该客户端之前是否来过，或发过什么请求。
    *   **优点:** 简化了服务器的设计，服务器无需为维护大量客户端的状态而分配内存，从而能支持更多的并发连接，提高了服务器的健壮性（即使服务器崩溃重启，也不影响新请求的处理）。
    *   **缺点:** 无法原生支持需要连续交互的应用，如购物车、用户登录等。为了实现这些功能，必须引入外部机制来管理状态。

*   **Cookies工作原理:** Cookies是Web站点用来在用户浏览器上存储少量信息，并在后续请求中取回这些信息的机制。
    *   **四个组成部分:**
        1.  HTTP响应报文中的`Set-Cookie:`**头部行**。
        2.  HTTP请求报文中的`Cookie:`**头部行**。
        3.  保存在客户端主机上，由浏览器管理的**Cookie文件或数据库**。
        4.  位于Web站点服务器端的**后端数据库**。
    *   **交互过程:**
        1.  **首次访问:** 当用户首次访问一个网站时，服务器会为该用户创建一个唯一的ID。
        2.  **服务器响应:** 服务器在HTTP响应报文中包含一个`Set-Cookie:`头部，内容为该用户的ID（如 `Set-Cookie: 1678`）。
        3.  **客户端存储:** 浏览器收到响应后，会解析`Set-Cookie:`头部，并在其管理的Cookie文件中为该网站存储这个ID。
        4.  **后续请求:** 当用户再次访问该网站的任何页面时，浏览器会在HTTP请求报文中自动添加一个`Cookie:`头部，并附上之前存储的ID（如 `Cookie: 1678`）。
        5.  **服务器识别:** 服务器通过读取请求中的Cookie ID，就能识别出这是之前的那个用户，并从后端数据库中检索该用户的状态信息（如购物车内容），从而提供个性化的服务。

**(b) HTTP性能计算:** (参考幻灯片 2-24, 2-25)
*   **参数:** RTT = 100 ms = 0.1 s, 带宽 = 10 Mbps。
*   HTML传输时间: $\frac{100 \text{ KB} \times 8 \text{ bits/Byte}}{10 \times 10^6 \text{ bps}} = \frac{8 \times 10^5 \text{ bits}}{10^7 \text{ bps}} = 0.08 \text{ s}$
*   JPEG传输时间: $\frac{500 \text{ KB} \times 8 \text{ bits/Byte}}{10 \times 10^6 \text{ bps}} = \frac{4 \times 10^6 \text{ bits}}{10^7 \text{ bps}} = 0.4 \text{ s}$

1.  **非持续HTTP:**
    *   需要建立 1 (HTML) + 10 (JPEG) = **11个独立的TCP连接**。
    *   每个对象的获取时间 = 1 RTT (建连) + 1 RTT (请求/响应) + 对象传输时间 = 2 RTT + 传输时间。
    *   获取HTML时间 = $2 \times 0.1 \text{ s} + 0.08 \text{ s} = 0.28 \text{ s}$。
    *   获取10个JPEG时间 = $10 \times (2 \times 0.1 \text{ s} + 0.4 \text{ s}) = 10 \times 0.6 \text{ s} = 6 \text{ s}$。
    *   总时间 (串行下载) = $0.28 \text{ s} + 6 \text{ s} = \mathbf{6.28 \text{ s}}$。
    *   (注: 实践中浏览器会并行打开多个TCP连接，但题目未说明，按串行计算最能体现非持续HTTP的理论开销。)

2.  **持续HTTP (带流水线):**
    *   只需要建立 **1个TCP连接**。
    *   连接建立时间 = 1 RTT = 0.1 s。
    *   客户端首先请求HTML文件，耗时 1 RTT (用于请求和接收响应的开始) + HTML传输时间。
    *   在收到HTML文件后，客户端立即以流水线方式发送对10个JPEG的请求。这些请求可以连续发送，无需等待前一个响应回来。
    *   总时间 ≈ 1 RTT (建连) + 1 RTT (请求HTML) + HTML传输时间 + 1 RTT (请求第一个JPEG) + 所有JPEG的总传输时间。
        *   (更精确的模型是: 建立连接后，请求HTML，收到HTML后，流水线发出10个请求，服务器流水线响应)
    *   简化模型计算:
        *   建立连接: 1 RTT
        *   请求和获取HTML: 1 RTT + HTML传输时间
        *   请求和获取10个JPEG: 1 RTT (发送第一个请求到收到第一个响应) + 10个JPEG的总传输时间
        *   总时间 = $1 \text{ RTT (建连)} + 1 \text{ RTT (请求HTML)} + \text{HTML传输时间} + 10 \times \text{JPEG传输时间}$
        *   总时间 = $0.1 \text{ s} + 0.1 \text{ s} + 0.08 \text{ s} + 10 \times 0.4 \text{ s} = 0.28 \text{ s} + 4 \text{ s} = \mathbf{4.28 \text{ s}}$。
    *   **结论:** 持续HTTP通过复用TCP连接，避免了多次建立连接的开销(10个RTT)，大大减少了总延迟。

---

#### **第三题：域名系统 (DNS) (25分)**

DNS是互联网的关键基础设施，负责将人类可读的主机名解析为机器可读的IP地址。

**(a) (8分)** 为什么因特网不采用集中式的DNS设计？请从可靠性、流量、维护性等方面进行阐述。

**(b) (17分)** 假设你的主机（`myhost.school.edu`）需要访问 `www.google.com`。你的主机配置的本地DNS服务器是 `dns.school.edu`。请详细描述一次 **迭代查询 (iterative query)** 的完整解析过程，说明你的主机、本地DNS服务器、根DNS服务器、TLD DNS服务器和权威DNS服务器各自在其中扮演的角色和交互步骤。

**【解析】**

**(a) 不采用集中式DNS的原因:** (参考幻灯片 2-59)
采用集中式DNS（即全球只有一个或少数几个中心DNS服务器）是不可行的，主要原因如下：
1.  **单点故障 (Single Point of Failure):** 如果这个唯一的DNS服务器宕机，整个互联网都将瘫痪。用户无法通过域名访问任何网站，可靠性极差。
2.  **流量巨大 (Traffic Volume):** 全球数十亿用户和设备产生的所有DNS查询请求都将涌向这个服务器，其负载将是天文数字，任何单一服务器都无法承受。
3.  **距离遥远 (Distant Centralized Database):** 用户可能与该中心服务器的物理距离非常远，导致DNS查询的延迟非常高，严重影响网页加载速度和用户体验。
4.  **维护困难 (Maintenance):** 维护一个包含全球所有主机名和IP地址映射的、需要频繁更新的巨大数据库，将是一项极其复杂和艰巨的任务。

因此，DNS采用了**分布式、分层**的设计，将管理权和负载分散到全球数百万个DNS服务器上，从而解决了上述所有问题，实现了高可靠性、可扩展性和高效性。

**(b) DNS迭代查询过程:** (参考幻灯片 2-61, 2-66)
整个过程的目标是 `myhost.school.edu` 找到 `www.google.com` 的IP地址。
1.  **主机发起查询 (步骤1):**
    *   `myhost.school.edu` 的应用程序（如浏览器）需要解析 `www.google.com`。操作系统首先检查本地缓存，若无记录，则向其配置的**本地DNS服务器** `dns.school.edu` 发送一个DNS查询请求。

2.  **本地DNS服务器开始迭代 (步骤2):**
    *   `dns.school.edu` 收到查询请求。它检查自己的缓存，假设也无记录。它将代表 `myhost` 去查询，它首先向一个**根DNS服务器**发送查询请求，询问 `www.google.com` 的IP地址。

3.  **根服务器响应 (步骤3):**
    *   根DNS服务器不知道 `www.google.com` 的IP地址，但它知道管理所有 `.com` 域的**TLD (顶级域) DNS服务器**的地址。于是，它向 `dns.school.edu` 回复一个列表，其中包含了 `.com` TLD服务器的IP地址。它会说：“我不知道，但你去问那些管 `.com` 的服务器”。

4.  **本地DNS服务器查询TLD服务器 (步骤4):**
    *   `dns.school.edu` 收到根服务器的响应后，选择其中一个 `.com` TLD服务器，并向它发送查询请求，询问 `www.google.com` 的IP地址。

5.  **TLD服务器响应 (步骤5):**
    *   `.com` TLD服务器也不知道 `www.google.com` 的IP地址，但它知道 `google.com` 域的**权威DNS服务器**的地址（这是Google公司自己管理的服务器）。于是，它向 `dns.school.edu` 回复一个列表，其中包含了 `google.com` 的权威DNS服务器的IP地址。它会说：“我不知道，但你去问 `google.com` 的权威服务器”。

6.  **本地DNS服务器查询权威服务器 (步骤6):**
    *   `dns.school.edu` 收到TLD服务器的响应后，选择其中一个 `google.com` 的权威DNS服务器，并向它发送查询请求，询问 `www.google.com` 的IP地址。

7.  **权威服务器响应 (步骤7):**
    *   `google.com` 的权威DNS服务器掌管着 `google.com` 域下所有主机的记录。它在自己的记录中找到了 `www.google.com` 对应的IP地址，并将这个**A记录**（IP地址）返回给 `dns.school.edu`。

8.  **本地DNS服务器返回结果给主机 (步骤8):**
    *   `dns.school.edu` 终于获得了 `www.google.com` 的IP地址。它首先将这个映射关系**缓存**起来，以备后续查询。然后，它将这个IP地址返回给最初发起请求的 `myhost.school.edu`。

9.  **主机访问目标:** 主机 `myhost.school.edu` 收到IP地址后，就可以向该IP地址发起HTTP请求了。

---

#### **第四题：Web缓存与内容分发网络(CDN) (25分)**

为了提升大规模内容分发的性能和效率，Web缓存和CDN技术被广泛应用。

**(a) (8分)** 解释Web缓存（或称代理服务器）为什么能减少用户的响应时间并降低机构接入链路的流量？Conditional GET机制在其中扮演了什么角色？

**(b) (9分)** 考虑一个场景：一个机构的接入链路速率为1.54 Mbps，从机构路由器到源服务器的RTT为2秒。Web对象平均大小为100 Kbits，机构内用户的平均请求速率为15个对象/秒。
1.  计算在**没有**Web缓存时，接入链路的利用率。根据利用率情况，判断此时的访问延迟会怎样？
2.  现在安装一个Web缓存，假设其命中率为40%。计算此时接入链路的利用率，并分析安装缓存后的效果。

**(c) (8分)** 解释CDN（内容分发网络）是如何在Web缓存的基础上，进一步解决向全球海量用户分发视频等大内容所面临的挑战的。请简述CDN的“深入”或“bring home”部署策略，并说明DASH（Dynamic, Adaptive Streaming over HTTP）技术如何与CDN协同工作。

**【解析】**

**(a) Web缓存与Conditional GET:** (参考幻灯片 2-36, 2-37, 2-42)
*   **Web缓存如何工作:**
    *   **减少响应时间:** Web缓存（通常部署在机构内部网络）存储了最近请求过的对象的副本。当有用户请求一个对象时，如果该对象在缓存中有副本，缓存会立即将其返回给用户，无需通过缓慢或拥塞的广域网接入链路去访问源服务器。由于缓存离用户更近，响应时间大大缩短。
    *   **降低链路流量:** 由于大量请求（缓存命中部分）都在本地得到满足，就不需要通过机构的接入链路去获取数据，从而显著减少了流出和流入接入链路的流量，为其他类型的网络应用节约了带宽。

*   **Conditional GET 的作用:**
    *   Conditional GET是一种优化机制，用于验证缓存中的对象副本是否仍然有效。当缓存需要确认副本是否过期时，它会向源服务器发送一个包含`If-Modified-Since`头部的HTTP GET请求。
    *   如果源服务器上的对象在此日期后**没有**被修改，服务器会返回一个状态码为`304 Not Modified`的空响应报文。缓存得知其副本仍然是新鲜的，可以直接使用，这样就避免了重新传输整个对象，极大地节约了带宽。
    *   如果对象**已被**修改，服务器则返回一个`200 OK`响应，并附上新的对象内容。

**(b) 场景计算:** (参考幻灯片 2-38, 2-41)
*   **参数:** 链路速率 R = 1.54 Mbps, 对象大小 L = 100 Kbits, 请求率 = 15 obj/s。
1.  **没有Web缓存:**
    *   所有请求都必须通过接入链路。
    *   接入链路上的流量强度 = 请求率 × 对象大小 = $15 \text{ obj/s} \times 100 \text{ Kbits/obj} = 1500 \text{ Kbits/s} = 1.5 \text{ Mbps}$。
    *   接入链路利用率 = $\frac{\text{流量强度}}{\text{链路速率}} = \frac{1.5 \text{ Mbps}}{1.54 \text{ Mbps}} \approx 0.974$。
    *   **延迟判断:** 利用率接近1（97.4%），这意味着链路非常繁忙。根据排队理论，当利用率趋近于1时，排队延迟会急剧增大，趋于无穷。因此，此时的访问延迟会**非常高**，用户体验会很差。

2.  **有Web缓存 (命中率40%):**
    *   只有60%的请求需要通过接入链路（因为40%的请求在缓存中命中）。
    *   新的接入链路流量强度 = $15 \text{ obj/s} \times (1 - 0.4) \times 100 \text{ Kbits/obj} = 15 \times 0.6 \times 100 = 900 \text{ Kbits/s} = 0.9 \text{ Mbps}$。
    *   新的接入链路利用率 = $\frac{0.9 \text{ Mbps}}{1.54 \text{ Mbps}} \approx 0.584$。
    *   **效果分析:** 安装缓存后，链路利用率从97.4%显著下降到58.4%，脱离了高拥塞区域。这会使得排队延迟大大降低，用户的平均响应时间得到极大改善，同时为其他应用释放了宝贵的带宽。

**(c) CDN与DASH:** (参考幻灯片 2-95, 2-96, 2-92)
*   **CDN如何扩展Web缓存:** CDN将Web缓存的思想从单个机构扩展到了全球范围。它通过在世界各地部署大量的缓存服务器（也称边缘节点），构建一个覆盖全球的分布式内容交付网络。当用户请求内容时，CDN会通过智能的流量导向机制（通常利用DNS），将用户引导到离他们**地理位置最近、网络延迟最低或负载最轻**的边缘服务器上获取内容。这解决了单个源服务器或单个缓存无法应对全球海量用户所带来的**延迟**和**带宽瓶颈**问题。

*   **部署策略:**
    *   **深入 (Enter Deep):** 将大量的小型服务器集群部署到全球成千上万个接入网（ISP）的内部，尽可能地靠近用户。如Akamai的策略。
    *   **Bring Home:** 在全球关键位置（如网络交换点PoPs）部署少量但规模巨大的服务器集群，服务于周边的接入网。如Limelight的策略。

*   **DASH与CDN协同工作:**
    *   DASH是一种客户端驱动的视频流技术。服务器将视频预先切分成多个小**块(chunks)**，并为每个块提供多种不同比特率（清晰度）的版本。
    *   DASH客户端（播放器）会持续监测自身的可用带宽，然后**智能地**向服务器请求合适比特率的视频块。
    *   CDN与DASH的结合堪称完美：CDN负责将所有不同比特率的视频块副本分发到离用户很近的边缘服务器上。当DASH客户端需要请求下一个视频块时，CDN的DNS系统会将其导向一个最优的边缘服务器，然后客户端根据当前网络状况，从这个近端的服务器上选择并下载最合适清晰度的视频块。这保证了用户在网络波动时也能获得流畅、快速、且质量动态自适应的观看体验。