好的，根据您提供的这份《计算机网络：自顶向下方法》第一章的PPT，我为您设计了五道适合期末考试的大题。这些题目旨在考察学生对核心概念的深入理解、比较分析以及解决问题的能力。

---

### **期末考试模拟题 (基于第一章)**

**说明:** 请详细回答以下问题，答案需要清晰、准确，并结合本章所学概念进行阐述。

---

#### **第一题：网络核心技术对比与计算 (20分)**

计算机网络的核心部分主要采用两种交换技术：电路交换（Circuit Switching）和分组交换（Packet Switching）。

**(a) (8分)** 请详细比较这两种交换技术的原理、主要优缺点。

**(b) (12分)** 假设有一个 `1 Gbps` 的链路，现在有若干用户共享此链路。每个用户在活动时，需要 `100 Mbps` 的固定带宽。每个用户只有10%的时间是活动的。
    1.  如果采用 **电路交换**，该链路最多可以支持多少个用户？请说明理由。
    2.  如果采用 **分组交换**，并假设可以支持35个用户，请从资源利用的角度解释为什么分组交换能支持比电路交换更多的用户。当用户数量非常多（例如超过100个）时，分组交换会面临什么主要问题？

**【解析】**

**(a) 对比分析:**
*   **电路交换 (Circuit Switching):**
    *   **原理:** 在数据传输开始前，必须在源和目标之间建立一条专用的、端到端的物理或逻辑电路。在整个通信期间，该电路的所有资源（如带宽、交换机缓存）被此连接独占，直到连接被释放。典型例子是传统的电话网络。
    *   **优点:**
        *   **性能保证:** 一旦电路建立，通信速率和延迟是固定且有保证的，不会因网络拥塞而波动。
        *   **实时性好:** 非常适合对延迟和抖动敏感的实时应用，如电话语音。
    *   **缺点:**
        *   **资源利用率低:** 即使用户没有数据发送，其占用的链路资源也无法被其他用户使用，造成浪费。特别不适合突发性数据（bursty data）。
        *   **建立连接开销:** 通信前有呼叫建立（call setup）的延迟。

*   **分组交换 (Packet Switching):**
    *   **原理:** 将要发送的报文分割成一个个较小的数据块，称为“分组”（Packet）。每个分组都包含头部信息（如目标地址）。分组在网络中独立传输，路由器采用“存储-转发”（store-and-forward）机制，根据分组头部信息进行路径选择。网络资源按需分配，多个用户的分组可以共享同一条链路。
    *   **优点:**
        *   **资源利用率高:** 链路资源由所有需要发送数据的用户共享，大大提高了链路利用率，非常适合突发性数据。
        *   **简单高效:** 无需建立连接，可以直接发送分组。
    *   **缺点:**
        *   **性能无保证:** 由于资源共享，当网络流量过大时，会导致排队延迟、抖动甚至分组丢失（丢包），无法提供严格的性能保证。
        *   **需要协议支持:** 需要更复杂的协议来处理拥塞控制和可靠数据传输。

**(b) 计算与分析:**
1.  **电路交换:** 在电路交换中，必须为每个用户预留其活动时所需的固定带宽。
    *   链路总带宽 = `1 Gbps` = `1000 Mbps`
    *   每个用户所需带宽 = `100 Mbps`
	    *   支持的用户数 = `总带宽 / 每个用户所需带宽` = `1000 Mbps / 100 Mbps` = **10个用户**。
    *   **理由:** 电路交换要求资源预留，无论用户是否真的在发送数据。为了保证每个用户在活动时都能获得`100 Mbps`的速率，我们只能同时为10个用户分配电路。

2.  **分组交换:**
    *   **支持更多用户的原因:** 分组交换利用了**统计多路复用（Statistical Multiplexing）**的原理。它基于一个事实：所有用户不可能在同一时刻都处于活动状态。虽然35个用户如果同时活动（`35 * 100 Mbps = 3.5 Gbps`）会远超链路容量，但这种情况发生的概率极低。因为每个用户只有10%的时间活动，分组交换允许资源在时间上由所有用户共享，从而能够接纳（admit）更多的用户，极大地提高了资源利用率。
    *   **用户过多时面临的问题:** 当用户数量非常多时，多个用户同时发送数据的概率会显著增加。这会导致：
        *   **网络拥塞（Congestion）:** 到达路由器的分组速率超过其转发速率，导致路由器输出链路的**队列（queue）**急剧增长。
        *   **排队延迟（Queueing Delay）:** 分组在队列中等待转发的时间变长，导致总的端到端延迟增加。
        *   **分组丢失（Packet Loss）:** 如果路由器的队列缓存（buffer）被占满，新到达的分组将被丢弃，造成丢包。

---

#### **第二题：网络时延分析 (20分)**

主机A通过一台路由器连接到主机B。A到路由器的链路速率为 `R1 = 100 Mbps`，路由器到B的链路速率为 `R2 = 1 Gbps`。A与路由器之间的距离为 `d1 = 100 km`，路由器与B之间的距离为 `d2 = 5 km`。信号在链路中的传播速度为 `s = 2.5 * 10^8 m/s`。假设主机A要向主机B发送一个大小为 `L = 1500` 字节（Byte）的文件。

**(a) (4分)** 请解释构成一个分组在网络中端到端时延的四个主要来源。

**(b) (16分)** 计算该文件（作为一个单独的分组）从A发送到B的端到端总时延。请分别计算并列出每一种时延的数值。（**假设处理时延和排队时延忽略不计**）

**【解析】**

**(a) 四种时延来源:** (参考幻灯片P48-49)
1.  **处理时延 (Processing Delay, d_proc):** 路由器或主机检查分组头部、决定输出链路以及检查比特错误所需的时间。通常是微秒级别。
2.  **排队时延 (Queueing Delay, d_queue):** 分组在输出链路的队列中等待被传输的时间。它取决于网络的拥塞程度，是唯一不固定的主要时延。
3.  **传输时延 (Transmission Delay, d_trans):** 将分组的所有比特“推”到链路中所需的时间。计算公式为 `L/R`，其中 `L` 是分组长度（比特），`R` 是链路带宽（bps）。
4.  **传播时延 (Propagation Delay, d_prop):** 一个比特从链路的一端传播到另一端所需的时间。计算公式为 `d/s`，其中 `d` 是物理链路的长度，`s` 是信号传播速度。

**(b) 计算总时延:**
总时延 `d_total = d_proc + d_queue + d_trans + d_prop`。根据题意，`d_proc` 和 `d_queue` 忽略不计。我们需要计算两段链路上的传输时延和传播时延之和。

首先，统一单位：
*   分组长度 `L = 1500` 字节 = `1500 * 8` 比特 = `12000` 比特。
*   链路速率 `R1 = 100 Mbps = 100 * 10^6` bps。
*   链路速率 `R2 = 1 Gbps = 1000 * 10^6` bps。
*   距离 `d1 = 100 km = 100 * 10^3` m。
*   距离 `d2 = 5 km = 5 * 10^3` m。
*   传播速度 `s = 2.5 * 10^8` m/s。

**1. A到路由器的时延:**
*   **传输时延1 (d_trans1):** `L / R1 = 12000 bits / (100 * 10^6 bps) = 0.00012 s = 0.12 ms`。
*   **传播时延1 (d_prop1):** `d1 / s = (100 * 10^3 m) / (2.5 * 10^8 m/s) = 0.0004 s = 0.4 ms`。

**2. 路由器到B的时延:**
*   **传输时延2 (d_trans2):** `L / R2 = 12000 bits / (1000 * 10^6 bps) = 0.000012 s = 0.012 ms`。
*   **传播时延2 (d_prop2):** `d2 / s = (5 * 10^3 m) / (2.5 * 10^8 m/s) = 0.00002 s = 0.02 ms`。

**3. 端到端总时延:**
由于是存储-转发，总时延是各部分时延之和。
`d_total = d_trans1 + d_prop1 + d_trans2 + d_prop2`
`d_total = 0.12 ms + 0.4 ms + 0.012 ms + 0.02 ms = 0.552 ms`。

**答：** 该文件从A发送到B的端到端总时延为 **0.552毫秒**。

---

#### **第三题：协议分层与封装 (20分)**

协议分层是网络体系结构的核心思想。

**(a) (10分)** 请描述因特网五层协议栈中每一层的主要功能，并指出每一层的数据单元（PDU）名称。

**(b) (10分)** 结合一个用户通过浏览器请求一个网页的实例，描述数据在发送方（Web服务器）从应用层到物理层是如何被**封装（Encapsulation）**的。

**【解析】**

**(a) 因特网五层协议栈:** (参考幻灯片P71)
1.  **应用层 (Application Layer):**
    *   **功能:** 为网络应用程序提供服务，支持应用程序间的数据交换。例如，HTTP（Web访问）、SMTP（邮件发送）、FTP（文件传输）。
    *   **PDU:** **报文 (Message)**。
2.  **运输层 (Transport Layer):**
    *   **功能:** 提供端到端（进程到进程）的数据传输服务。主要协议有TCP（可靠、面向连接）和UDP（不可靠、无连接）。
    *   **PDU:** **报文段 (Segment)** (用于TCP) 或 **用户数据报 (User Datagram)** (用于UDP)。
3.  **网络层 (Network Layer):**
    *   **功能:** 负责将分组（数据报）从源主机路由到目的主机。主要协议是IP协议，它负责主机的寻址和数据报的路由。
    *   **PDU:** **数据报 (Datagram)**。
4.  **链路层 (Link Layer):**
    *   **功能:** 在相邻网络节点（如主机和路由器）之间提供数据传输服务。它将网络层的数据报封装成帧，在本地网络中进行传输。
    *   **PDU:** **帧 (Frame)**。
5.  **物理层 (Physical Layer):**
    *   **功能:** 负责在传输媒介上传输原始的比特流。它定义了接口的电气、机械和功能特性。
    *   **PDU:** **比特 (Bit)**。

**(b) 封装过程描述:** (参考幻灯片P72-76)
当Web服务器响应用户的网页请求时，数据封装过程如下：
1.  **应用层:** 服务器的Web应用程序（如Apache）创建一个HTTP响应**报文（Message）**，其中包含状态码（如`200 OK`）和网页的HTML内容。这个报文被向下传递给运输层。
2.  **运输层:** 运输层（通常是TCP协议）接收到HTTP报文。它会在报文前添加一个**TCP头部**（包含源端口和目的端口号等信息），形成一个**TCP报文段（Segment）**。这个头部用于在客户端和服务器进程之间建立连接和保证数据可靠传输。报文段被向下传递给网络层。
3.  **网络层:** 网络层（IP协议）接收到TCP报文段。它会在报文段前添加一个**IP头部**（包含源IP地址和目的IP地址等信息），形成一个**IP数据报（Datagram）**。这个头部用于在整个互联网中找到目标主机。数据报被向下传递给链路层。
4.  **链路层:** 链路层（如以太网协议）接收到IP数据报。它会在数据报前添加一个**链路层头部**（包含下一跳的MAC地址），并在末尾添加一个**尾部**（用于差错校验），形成一个**帧（Frame）**。这个帧用于在本地网络中将数据从服务器传递到第一个路由器。
5.  **物理层:** 物理层接收到帧，并将帧中的比特流转换成电信号（或光信号、无线电信号），通过物理媒介（如网线）发送出去。

这个过程就像套娃（Matryoshka dolls），每一层都将上一层的数据作为自己的“载荷”，并加上自己的控制信息（头部），然后传递给下一层。

---

#### **第四题：吞吐量与瓶颈链路 (20分)**

**(a) (4分)** 什么是吞吐量（Throughput）？什么是瓶颈链路（Bottleneck Link）？

**(b) (16分)** 考虑以下两种网络场景：
    1.  一台服务器通过一条速率为 `Rs` 的链路连接到网络，客户端通过一条速率为 `Rc` 的链路连接到网络。网络核心部分的速率远高于 `Rs` 和 `Rc`。请问在 `Rs < Rc` 和 `Rs > Rc` 两种情况下，从服务器到客户端的端到端吞吐量分别是多少？
    2.  如下图所示，10个客户端（每个客户端的接入链路速率为 `Rc`）和1个服务器（接入链路速率为 `Rs`）通过一个共享的骨干链路（速率为 `R`）连接。假设 `Rs = 200 Mbps`，`Rc = 100 Mbps`，`R = 1 Gbps`。如果这10个客户端同时从该服务器下载文件，并且骨干链路的带宽被公平共享，请问每个客户端的下载吞吐量是多少？请说明分析过程。
         (此图为对PPT P58的文字描述)

**【解析】**

**(a) 定义:**
*   **吞吐量 (Throughput):** 指在单位时间内，从发送方成功传输到接收方的数据量，单位通常是 bps (bits per second)。它可以是瞬时吞吐量或平均吞吐量。
*   **瓶颈链路 (Bottleneck Link):** 在一条端到端的路径上，限制了端到端吞吐量的那个链路，即路径上速率最低的链路。

**(b) 场景分析:**
1.  **简单场景:** 端到端的吞吐量由路径上的瓶颈链路决定。
    *   当 `Rs < Rc` 时，服务器的发送速率 `Rs` 是瓶颈。因此，端到端吞吐量为 **`Rs`**。
    *   当 `Rs > Rc` 时，客户端的接收速率 `Rc` 是瓶颈。因此，端到端吞吐量为 **`Rc`**。
    *   综上，吞吐量为 `min(Rs, Rc)`。

2.  **共享链路场景:**
    *   **分析过程:** 每个客户端的端到端路径由三部分组成：服务器的接入链路（`Rs`）、共享的骨干链路（`R`），以及客户端自己的接入链路（`Rc`）。
    *   **服务器能力:** 服务器的总发送能力为 `Rs = 200 Mbps`。
    *   **骨干链路能力:** 骨干链路的总容量为 `R = 1 Gbps = 1000 Mbps`。由于有10个客户端公平共享，每个客户端能分到的骨干链路带宽为 `R / 10 = 1000 Mbps / 10 = 100 Mbps`。
    *   **客户端能力:** 每个客户端的接收能力为 `Rc = 100 Mbps`。
    *   **瓶颈分析:** 对于**每一个**客户端，其数据流能达到的最大速率受限于其路径上所有环节的最小值。
        `吞吐量 = min(服务器总发送能力, 单个客户端的骨干链路份额, 客户端接收能力)`
        `吞吐量 = min(Rs, R/10, Rc)`
        但是，这里需要注意，`Rs`是服务器的总出口带宽，被10个客户端共享。所以服务器能提供给**每个**客户端的平均速率是 `Rs / 10 = 200 Mbps / 10 = 20 Mbps`。
        因此，每个客户端的路径瓶颈应该是：
        `吞吐量 = min(服务器能为该连接提供的速率, 该连接在骨干链路上的份额, 客户端接收速率)`
        `吞吐量 = min(Rs/10, R/10, Rc)`
        `吞吐量 = min(200/10 Mbps, 1000/10 Mbps, 100 Mbps)`
        `吞吐量 = min(20 Mbps, 100 Mbps, 100 Mbps)`
        `吞吐量 = 20 Mbps`
    *   **结论:** 每个客户端的下载吞吐量是 **20 Mbps**。瓶颈在于服务器的接入链路带宽 `Rs`，它无法同时满足所有客户端的高速下载需求。

---

#### **第五题：网络安全威胁与防御 (20分)**

**(a) (6分)** 幻灯片中提到“因特网最初的设计并未过多考虑安全”。请解释这一说法的历史背景和原因。

**(b) (14分)** 请描述以下三种网络攻击的工作原理，并为每种攻击提出一种相应的防御机制。
    1.  分组嗅探 (Packet Sniffing)
    2.  IP欺骗 (IP Spoofing)
    3.  拒绝服务攻击 (Denial of Service, DoS)

**【解析】**

**(a) 历史背景:** (参考幻灯片P60)
因特网的前身是ARPANET，它诞生于冷战时期，最初的设计目标是连接美国的少数大学和研究机构。当时的网络环境具有以下特点：
*   **用户群体小且可信:** 用户都是经过审查的科研人员和学者，大家相互信任。
*   **网络封闭:** 网络是封闭的，并未向公众开放，不存在来自外部的恶意攻击者。
*   **目标是连通性:** 首要设计目标是确保网络的健壮性和在部分节点失效时的连通性，而非安全性。
因此，当时的协议设计，如TCP/IP，都建立在“一个互相信任的用户群体连接到一个透明网络”的设想之上，缺乏内置的身份认证、加密等安全机制。随着90年代互联网的商业化和全球化，大量不受信任的用户接入，这些早期设计上的“安全缺失”就成为了各种网络攻击的温床。

**(b) 攻击与防御:** (参考幻灯片P62-65)
1.  **分组嗅探 (Packet Sniffing):**
    *   **原理:** 攻击者将自己主机的网络接口设置为“混杂模式”（Promiscuous Mode），在共享介质（如早期的集线器网络、未加密的Wi-Fi）上，这个接口会接收并记录所有流经该介质的数据分组，而不仅仅是发给自己的。如果数据是明文传输的（如早期的Telnet, HTTP, FTP），攻击者就可以窃取密码、邮件内容等敏感信息。
    *   **防御机制:** **加密 (Encryption)**。通过使用加密协议（如HTTPS代替HTTP，SSH代替Telnet，WPA2/WPA3用于Wi-Fi），可以确保即使分组被嗅探，其内容也是加密的密文，攻击者无法解读。这是保证**机密性（Confidentiality）**的关键。

2.  **IP欺骗 (IP Spoofing):**
    *   **原理:** 攻击者创建一个IP数据报，并将其源IP地址伪造成另一个合法主机的地址。这样，接收方会误以为数据报来自那个被伪造的主机。这种攻击常被用于绕过基于IP地址的防火墙规则，或者在DoS攻击中隐藏攻击源。
    *   **防御机制:** **身份认证 (Authentication)** 和 **入口/出口过滤 (Ingress/Egress Filtering)**。
        *   **身份认证:** 在应用层或运输层使用更强的身份验证机制（如数字签名、安全令牌），不单纯依赖IP地址来判断身份。
        *   **入口过滤:** 网络运营商在其网络边缘的路由器上配置规则，拒绝那些源IP地址明显不属于其客户网络的“伪造”数据包进入其网络。

3.  **拒绝服务攻击 (Denial of Service, DoS):**
    *   **原理:** 攻击者通过发送大量无用的、伪造的或格式错误的请求，耗尽目标服务器或网络的资源（如带宽、CPU、内存、连接数），使得合法用户无法正常访问服务。常见的形式是带宽耗尽型攻击（如UDP洪水）或连接耗尽型攻击（如SYN洪水）。
    *   **防御机制:** **防火墙 (Firewalls)** 和 **入侵检测/防御系统 (IDS/IPS)**。
        *   **防火墙/IDS:** 可以配置规则来过滤掉来自已知恶意源的流量，或者识别出DoS攻击的流量模式（如短时间内大量来自不同源的SYN请求），并进行阻断或限速。
        *   **流量清洗服务:** 在大规模的分布式DoS (DDoS) 攻击面前，通常需要借助专业的流量清洗服务，将流量重定向到清洗中心，过滤掉恶意流量后再将干净的流量送回目标服务器。