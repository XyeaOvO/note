## 5.1 基本概念 💡

### 引言
数字通信的核心是传输**数字 (digit)**，尤其以**二进制数字 (binary digit, bit)** 为主。
可以将数字通信过程形象地想象为一个“比特管道”：
`1011001...` ➡ ❓ ➡ `1011001...`

一个典型的**数字基带传输系统**包括：
![](Pic/Pasted%20image%2020250506215426.png)
本章主要关注：**数字信号 (PAM)**、**功率谱密度 (Power Spectral Density)**、**码间串扰 (ISI - Inter-Symbol Interference)**。

### 如何度量和表示信息？ 🤔
信息是消息中所包含的有意义的内容，其量值（信息量）取决于相应事件发生的**不确定性**。
*   设 $P(x)$ 为事件 $x$ 发生的概率。
*   设 $I(x)$ 为事件 $x$ 所含的信息量。
则 $I(x) = f[P(x)]$，并且 $I(x)$ 应满足以下性质：
1.  **非负性**: $I(x) \ge 0$
2.  **单调性**: 事件发生的概率越小，其信息量越大。即 $I(x)$ 是关于 $P(x)$ 的单调递减函数。
3.  **确定性**: 若 $P(x) = 1$ (确定事件)，则 $I(x) = 0$。
4.  **不可能事件**: 若 $P(x) = 0$ (不可能事件)，则 $I(x) = \infty$。（严格来说，当$P(x) \to 0^+$时，$I(x) \to \infty$）
5.  **可加性**: 对于 $n$ 个相互独立的事件 $x_1, x_2, \ldots, x_n$，其联合信息量等于各自信息量之和：
    $$I(x_1, x_2, \ldots, x_n) = I(x_1) + I(x_2) + \cdots + I(x_n)$$

#### 单个事件的信息量 (自信息, Self-information) 😯
自信息衡量的是：
*   事件发生前的不确定性。
*   事件发生后所提供的信息量。
也常被称为“惊奇度 (Surprisal)”。

定义式为：
$$I(x) = \log_a \frac{1}{P(x)} = -\log_a P(x)$$
单位取决于对数底 $a$ 的选择：
*   $a=2$: **比特 (bit)** 👍 (最常用)
*   $a=e$: **奈特 (nit)**
*   $a=10$: **哈特莱 (Hartley)**

对于 $n$ 个独立事件 $x_1, x_2, \ldots, x_n$，联合概率 $P(x_1, \ldots, x_n) = P(x_1)P(x_2)\cdots P(x_n)$。
其总信息量为：
$$I(x_1, \ldots, x_n) = -\log_a [P(x_1)P(x_2)\cdots P(x_n)] = \sum_{i=1}^n [-\log_a P(x_i)] = \sum_{i=1}^n I(x_i)$$
这满足了前面提到的可加性。

#### 多个事件的平均信息量 (信息熵, Information Entropy) 📊
🧠 **知识回顾**: 信息熵是概率论和信息论中的一个核心概念，衡量一个随机变量不确定性的平均度量。

考虑一个离散信源 $X$，它可以发出 $M$ 个不同的符号 $\{x_1, x_2, \ldots, x_M\}$。
每个符号 $x_i$ 发生的概率为 $P(x_i)$，其自信息量为 $I(x_i) = -\log_2 P(x_i)$ (通常在通信中，信息熵的对数底取2)。

信源 $X$ 的**信息熵** $H(X)$ 定义为所有可能符号的自信息量的统计平均值：
$$ \boxed{ H(X) = E[I(x)] = \sum_{i=1}^M P(x_i) I(x_i) = -\sum_{i=1}^M P(x_i) \log_2 P(x_i) } $$
单位通常是 **bit/符号 (bit/symbol)**。

**特殊情况**: 如果信源有 $M$ 个符号，且所有符号独立等概出现，即 $P(x_i) = 1/M$ for all $i$。
若 $M=2^k$ (即每个符号可以由 $k$ 个比特唯一表示)，则：
$$H(X) = -\sum_{i=1}^M \frac{1}{M} \log_2 \frac{1}{M} = -M \left( \frac{1}{M} (-\log_2 M) \right) = \log_2 M = k \text{ bit/symbol}$$
这意味着当符号等概时，每个符号平均携带的信息量最大，等于表示该符号所需的比特数。

### 比特与符号 🪙
*   **比特 (Bit)**: 是拟传输的**信息**的基本单位。
*   **符号 (Symbol)**: 是比特的**载体或表现形式**。比特必须通过符号来表示和传输。
    *   符号可以是多种多样的：图形、文字、手势、表情、声音、电平、波形等。
    *   在数字通信中，符号通常是**电波形 (electrical waveform)**。

例如：
*   一个**二进制符号** (如高电平/低电平) 可以表示 **1个比特**。
*   一个**四进制符号** (如四种不同幅度的电平) 可以表示 **2个比特**。

关系图：
`比特 (Bits)` ➡ (发端：变成波形) ➡ `符号 (Symbols)` ➡ (信道) ➡ (收端：识别数据) ➡ `比特 (Bits)`

#### 数字信号——用电波形设计的符号 〰️
*   **例1: 二进制设计 (Binary Design)**
    用两种不同的波形（或电平）表示0和1。
    例如，传输序列 `0 1 1 1 0 0 1 0`。
    特点：每个符号传输1比特，符号变化速率较快，但“一次传的少”。

*   **例2: 四进制设计 (Quaternary Design)**
    用四种不同的波形（或电平）表示两位比特组合 (例如，00, 01, 10, 11)。
    例如，传输序列 `01 11 00 10` (这里每个数字对代表一个四进制符号)。
    特点：每个符号传输2比特，符号变化速率可以相对较慢，但“一次传的多”。

一个 $M$ 进制的符号可以携带 $k = \log_2 M$ 个比特的信息。
假设要传输 3600 个比特：
*   **二进制传输 ($M=2, k=1$)**: 需要执行 3600 次“发送1个比特”的操作（即发送3600个二进制符号）。
*   **四进制传输 ($M=4, k=2$)**: 需要执行 1800 次“发送2个比特”的操作（即发送1800个四进制符号）。
*   **八进制传输 ($M=8, k=3$)**: 需要执行 1200 次“发送3个比特”的操作（即发送1200个八进制符号）。
*   **$M=2^k$ 进制传输**: 需要执行 $3600/k$ 次“发送 $k$ 个比特”的操作。

结论：一个 $M$ 进制符号携带 $\log_2 M$ 个比特。

### 比特相关参数 🅱️
比特流以均匀的节奏进入“管道”，到达收端。
*   **比特速率 (Bit Rate) $R_b$**: 平均每秒钟传输的比特数。单位：bit/s 或 bps。
*   **比特间隔 (Bit Interval) $T_b$**: 平均每传输一个比特所需的时间。
    $$T_b = \frac{1}{R_b}$$
*   **比特能量 (Bit Energy) $E_b$**: 平均每发送一个比特所消耗的能量。单位：焦耳 (J)。
*   **误比特率 (Bit Error Rate) $P_b$ (BER)**: 比特流在传输过程中发生错误的比例，也称误码率。
    $$P_b = \frac{\text{错误比特数}}{\text{总比特数}}$$
*   **频带利用率 (Bandwidth Efficiency) $\eta_b$**: 平均每1Hz频带实现的比特速率，也称频谱效率 (spectral efficiency) 或谱效。
    $$\eta_b = \frac{R_b}{B}$$
    单位：bps/Hz 或 (bit/s)/Hz。

### 符号相关参数 💲
在“管道”内部，节奏均匀的比特流转换成了节奏均匀的符号流。
*   **符号速率 (Symbol Rate) $R_s$**: 平均每秒钟传输的符号数。单位：symbol/s，也记为 **波特 (Baud)**。符号速率也叫 **码元速率**。
*   **符号间隔 (Symbol Interval) $T_s$**: 平均每传输一个符号所需的时间。也叫 **码元间隔**。
    $$T_s = \frac{1}{R_s}$$
*   **符号能量 (Symbol Energy) $E_s$**: 平均每发送一个符号所消耗的能量。单位：焦耳 (J)。
*   **误符号率 (Symbol Error Rate) $P_s$ (SER)**: 传输的符号中，在接收端出错的符号的比例。也叫误码率 (为避免与BER混淆，称SER更准确)。
    $$P_s = \frac{\text{错误符号数}}{\text{总符号数}}$$
*   **(基于符号的)频带利用率 $\eta_s$**: 平均每1Hz频带实现的符号速率。
    $$\eta_s = \frac{R_s}{B}$$
    单位：Baud/Hz。

### $M$进制与二进制参数转换 🔄
一个 $M$ 进制符号携带 $k = \log_2 M$ 个比特。
*   **速率关系**:
    $$R_s = \frac{R_b}{\log_2 M} \quad \Leftrightarrow \quad R_b = R_s \cdot \log_2 M$$
*   **间隔关系**:
    $$T_s = T_b \cdot \log_2 M \quad \Leftrightarrow \quad T_b = \frac{T_s}{\log_2 M}$$
*   **能量关系**:
    $$E_s = E_b \cdot \log_2 M \quad \Leftrightarrow \quad E_b = \frac{E_s}{\log_2 M}$$
*   **频带利用率关系 (以比特/秒/赫兹为单位)**:
    $$\eta_b = \frac{R_b}{B} = \frac{R_s \cdot \log_2 M}{B} = \eta_s \cdot \log_2 M$$

这些关系意味着：
*   **给定比特速率 $R_b$**: 进制数 $M$ 越高 (即 $\log_2 M$ 越大)，则符号速率 $R_s$ 越低。
*   **给定符号速率 $R_s$**: 进制数 $M$ 越高，则比特速率 $R_b$ 越高。
*   **给定比特能量 $E_b$**: 进制数 $M$ 越高，则符号能量 $E_s$ 越大。
*   **给定符号速率 $R_s$ 及带宽 $B$**: 进制数 $M$ 越高，则按 bps/Hz 计算的频带利用率 $\eta_b$ 越高。

### 误符号率 ($P_s$) 与误比特率 ($P_b$) 的关系 📉📈
一个 $M$ 进制符号对应 $k = \log_2 M$ 个比特。
*   当一个符号发生错误 (Symbol Error) 时，其对应的 $k$ 个比特中，至少有 **1个** 比特是错误的，最多有 **$k$个** 比特全部错误。
*   设 $N_{s}$ 为传输的总符号数，$N_{b} = k N_{s}$ 为传输的总比特数。
*   设 $N_{es}$ 为错误符号的数目，$N_{eb}$ 为错误比特的数目。
*   根据上述，有 $N_{es} \le N_{eb} \le k \cdot N_{es}$。
*   误符号率 $P_s = N_{es} / N_s$。
*   误比特率 $P_b = N_{eb} / N_b = N_{eb} / (k N_s)$。

将 $N_{es} \le N_{eb} \le k \cdot N_{es}$ 各项除以 $k N_s$:
$$ \frac{N_{es}}{k N_s} \le \frac{N_{eb}}{k N_s} \le \frac{k \cdot N_{es}}{k N_s} $$
代入 $P_s$ 和 $P_b$ 的定义 ($N_{es} = P_s N_s$):
$$ \boxed{ \frac{P_s}{\log_2 M} \le P_b \le P_s } $$
其中 $k = \log_2 M$。

(等价于 $P_b \le P_s \le P_b \cdot \log_2 M$，这也是一种有效的界限关系。)